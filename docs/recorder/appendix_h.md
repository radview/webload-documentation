# Glossary



|**Glossary Term**|**Description**|
| :- | :- |
|**AAT**|An older, obsolete WebLOAD utility that was used for recording web session activities as a JavaScript file. It is replaced by WebLOAD Recorder.|
|**Aborted Rounds**|The number of times the Virtual Clients started to run a script but did not complete the script, during the last reporting interval. This might be due to a session being stopped either automatically or manually by the user.|
|**Script**|Specification of the sequence of HTTP protocol calls sent by Virtual Clients to the SUT (System Under Test). scripts are written in JavaScript. You can either write scripts as a text file or generate them automatically using the WebLOAD Recorder.|
|**Application Being Tested (ABT)**|See [*SUT*.](#_bookmark387)|
|**Attempted Connections**|The total number of times the Virtual Clients attempted to connect to the SUT during the last reporting interval.|
|**Automatic Transaction counters**|<p>If you have Automatic Transactions enabled, WebLOAD creates three counters for each GET and POST statement in the script:</p><p>- The total number of times it occurred</p><p>- The number of times it succeeded</p><p>- The number of times it failed during the last reporting interval.</p>|
|**Average**|For timers, average is the total amount of time counted by the timer (not the elapsed time) divided by the Count (that is, the total number of readings). For example, the average for Transaction Time is the amount of time it took to complete all the successful transactions, divided by the number of successful transactions (the Count).|
|**Built-in Timer**|A timer measures the time required to perform a given task. WebLOAD supports both programmed timers and built-in timers. ROUND TIME is a built-in timer. The ROUND TIME is the time needed for one complete execution of a script.|
| **Connect Time**                                  | <p>The time it takes for a Virtual Client to connect to the System Under Test (the SUT), in seconds. In other words, the time it takes from the beginning of the HTTP request to the TCP/IP connection.</p><p>The value posted in the Current Value column is the average time it took a Virtual Client to connect to the SUT during the last reporting interval.</p><p>If the Persistent Connection option is enabled, there may not be a value for Connect Time because the HTTP connection remains open between successive HTTP requests.</p> |
|**Connection Speed (Bits Per Second)**|<p>The number of bits transmitted back and forth between the Virtual Clients and the System Under Test (SUT), divided by the time it took to transmit those bits, in seconds.</p><p>You can set the Virtual Clients to emulate a particular connection speed during the test, either by using the Variable Connection Speed settings, or by coding the connection speed in the script.</p><p>If a connection speed is specified for the test, WebLOAD reports it in the Statistics Report.</p><p>The value posted in the Current Value column is the number (sum) of bits passed per second during the last reporting interval. It should match, very closely, the connection speed you specified for the test.</p>|
<a name = "_bookmark379"></a>
**Console**|<p>The WebLOAD component that manages the test session.</p><p>The Console performs the following:</p><p>- Configures Load Session hosts and scripts</p><p>- Schedules Load Session scripts</p><p>- Configures Goal–Oriented test sessions</p><p>- Monitors the application's performance under the generated load</p><p>- Manages the Load Session as it is running, allowing you to pause, stop, and continue Load Session components as needed</p><p>- Displays the current performance of the SUT</p><p>- Provides a final performance reports for Probing Clients and Virtual Clients</p><p>- Manages exporting of performance reports</p>|
|**Count**|(For timers only.) The  total number of readings (the number of times the item being timed has  occurred) for the timed statistic since the beginning of the test. For  example, for Transaction Time, Count shows the number of transactions that  have been completed.|
|**Current  Slice**|The value posted for this reporting  interval in the Statistics Report main window.|
|**Current  Slice Average**|For per time unit statistics and counters, average is the total of  all of the current values for the last reporting interval, divided by the  number of readings.  For timers, average is the  total amount of time counted by the timer (not the elapsed time), divided by  the Count (that is, the total number of readings for the last reporting  interval). For example, the average for Transaction Time is the amount of  time it took to complete all the successful transactions in the last  reporting interval, divided by the number of successful transactions (the  Current Slice Count).|
|**Current  Slice Count**|(For timers only.) The total number of  readings (the number of times the item being timed has occurred) for the  timed statistic for the last reporting interval. For example, for Transaction  Time, Current Slice Count shows the number of transactions that have been  completed over the last reporting interval.|
|**Current  Slice Max**|The highest value reported for this statistic over the last reporting  interval.|
|**Current  Slice Min**|The lowest value reported for this statistic over the last reporting  interval.|
|**Current  Slice Standard Deviation**|The average amount the measurement for this statistic varies from the  average over the last reporting interval.|
|**Current  Slice Sum**|The aggregate or total  value for this statistic in this script over the last reporting interval.|
|**DNS Lookup  Time**|The time it takes to  resolve the host name and convert it to an IP address by calling the DNS  server.|
|**Failed Connections**|The total number of times  the Virtual Clients tried to connect to the SUT but were unsuccessful, during  the last reporting interval.  This number is always less  than or equal to the number of failed hits because hits can fail for reasons  other than a failed connection.|
|**Failed Hits**|The total number of times the Virtual Clients made an HTTP request but did not receive the correct HTTP response from the SUT during the last reporting interval. Note that each request for each gif, jpeg, html file, etc., is a single hit.|
|**Failed Hits Per Second**|<p>The number of times the Virtual Clients did not obtain the correct HTTP response, divided by the elapsed time, in seconds.</p><p>The value posted in the Current Value column is the number (sum) of unsuccessful HTTP requests per second during the last reporting interval.</p>|
|**Failed Pages Per Second**|<p>The number of times the Virtual Clients did not obtain the correct response to an upper level request, divided by the elapsed time, in seconds.</p><p>The value posted in the Current Value column is the number (sum) of unsuccessful requests per second during the last reporting interval.</p>|
|**Failed Rounds**|The total number of times the Virtual Clients started but did not complete the script during the last reporting interval.|
|**Failed Rounds Per Second**|The number of times the Virtual Clients started but did not complete an iteration of the script, divided by the elapsed time, in seconds. The value posted in the Current Value column is the number (sum) of failed iterations of the script per second during the last reporting interval.|
|**First Byte**|The time it takes a Virtual Client to receive the first byte of data.|
|**Gallery**|See [*Templates Gallery*.](#templates_gallery)|
|<a name="goal_oriented_test"></a>**Goal–Oriented Test**|<p>A WebLOAD component enabling you to define the performance goals required, and view the status of your application when it is operating under this performance goal. WebLOAD provides a Goal–Oriented Test Wizard for configuring these performance goals. WebLOAD automatically accelerates the number of Virtual Clients accessing your website until you meet your performance goal.</p><p>**Note:** The Goal-Oriented Test Wizard was previously called the Cruise Control Wizard.</p>|
|**Goal–Oriented Test Wizard**|See [*Goal–Oriented Test*.](#goal_oriented_test)|
|**Hit Time**|<p>The time it takes to complete a successful HTTP request, in seconds. Each request for each gif, jpeg, html file, etc., is a single hit. The time of a hit is the sum of the Connect Time, Send Time, Response Time, and Process Time.</p><p>The value posted in the Current Value column is the average time it took to make an HTTP request and process its response during the last reporting interval.</p>|
|**Hits**|<p>The total number of times the Virtual Clients made HTTP requests to the System Under Test (SUT) during the last reporting interval.</p><p>For example, a Get statement for a URL retrieves a page. The page can include any number of graphics and contents files. Each request for each gif, jpeg, html file, etc., is a single hit.</p>|
|**Hits Per Second**|<p>The number of times the Virtual Clients made an HTTP request, divided by the elapsed time, in seconds. Each request for each gif, jpeg, html file, etc. is a single hit.</p><p>The value posted in the Current Value column is the number (sum) of HTTP requests per second during the last reporting interval.</p>|
|**Host**|A computer connected via a network, participating in a test session. Each Host in a test session has assigned tasks. A host can act as either a Load Machine or a Probing Client Machine. All hosts participating in a test session must be accessible to the Console over a network. Therefore they must run TestTalk, the network agent.|
|**HTTP Response Status**|<p>WebLOAD creates a row in the Statistics Report for each kind of HTTP status code it receives as an HTTP response from the SUT (redirection codes, success codes, server error codes, or client error codes).</p><p>The value posted is the number of times the Virtual Clients received that status code during the last reporting interval.</p>|
|**Integrated Report**|A single configurable report that can integrate both standard performance data, and data from the NT Performance Monitor. This report gives you a more complete picture of the performance of your application. The data to be monitored and the data to be displayed in the report are both configurable in the Console.|
|**Internet Productivity Pack (IPP)**|Provides a set of protocol implementations enabling you to load-test your application using these protocols.|
|**Java and ActiveX counters**|<p>You can add function calls to your scripts that enable you to instantiate and call methods and properties in Java and ActiveX components (see the *WebLOAD Scripting Guide*). If there are ActiveX or Java function calls in the script that you are running, WebLOAD reports three counters for them in the Statistics Report:</p><p>- The total number of times it occurred</p><p>- The number of times it succeeded</p><p>- The number of times it failed during the last reporting interval.</p><p>The row heading in the Statistics Report is the name of the function call.</p>|
|**Java and ActiveX timers**|<p>You can add function calls to your scripts that enable you to instantiate and call methods and properties in Java and ActiveX components (see the *WebLOAD Scripting Guide*). If there are ActiveX or Java function calls in the script you are running, WebLOAD reports timers for them in the Statistics Report.</p><p>The timer value is the average amount of time it took to complete the function call, in seconds, during the last reporting interval.</p><p>The row heading in the Statistics Report is the name of the function call.</p>|
|**Load Generator**|The component of the Load Machine that generates Virtual Clients. Load Generators have the task of bombarding the System Under Test with HTTP protocol call requests as defined in the script. WebLOAD assesses the application's performance by measuring the response time experienced by the Virtual Clients. The number of Virtual Clients at any given moment is determined by the user.|
|**Load Generator Machine**|See [*Load Machine*.](#load_machine)|
|<a name="load_machine"></a>
**Load Machine**|A host that runs Load Generators. Load Generators bombard the application under test with a large load, to enable complete scalability and integrity testing.|
|<a name="load_sessions"></a>
**Load Session**|<p>A Load Session includes both the complete Load Template and the results obtained while running that Load Session. A Load Template consists of information about the hosts and scripts participating in the current Load Session. The Load Template will also include scheduling information. The complete Load Template is illustrated in the Session Tree. Storing a Load Template saves you time when repeatedly running WebLOAD with the same, or even a similar network configuration, since you don't have to recreate your Load Template from scratch each time you want to start working.</p><p>Storing Load Session results can be useful when you want to examine results from multiple test sessions or for analyzing test session results.</p>|
|**Load Size**|The number of Virtual Clients running during the last reporting interval.|
|<a name="load_template"></a>
**Load Template**|A Load Template contains the complete Load Session definition, without the test results. A Load Template includes information about the participating hosts and the scripts used in the current Load Session. The definition also includes scheduling information and the configuration of the Server Monitor and Integrated Reports. The complete Load Template is illustrated in the Session Tree. Storing a Load Template saves you time when repeatedly running WebLOAD with the same, or even a similar network configuration, since you do not have to recreate your Load Template from scratch each time you rerun a test.|
|**Page Time**|<p>The time it takes to complete a successful upper level request, in seconds. The Page Time is the sum of the Connection Time, Send Time, Response Time, and Process Time for all the hits on a page.</p><p>The value posted in the Current Value column is the average time it took the Virtual Clients to make an upper level request and process its response during the last reporting interval.</p>|
|**Pages**|The total number of times the Virtual Client made upper level requests, both successful and unsuccessful, during the last reporting interval.|
|**Pages Per Second**|<p>The number of times the Virtual Clients made upper level requests divided by the elapsed time, in seconds.</p><p>The value posted in the Current Value column is the number (sum) of requests per second during the last reporting interval.</p>|
|Per Time Unit statistics|Ratios that calculate an average value for an action or process. For example: Transactions Per Second, Rounds Per Second.|
|<a name="_bookmark384"></a>**Portfolio**|A Portfolio of reports enables you to generate a single, inclusive report that contains all the charts generated by the templates included in the portfolio.|
|<a name="_bookmark385"></a>**Probing Client**|A software program which "bombards" the SUT as a single Virtual Client, to further measure the performance of the SUT. WebLOAD generates exact values for Probing Client performance.|
|**Probing Client Machines**|Hosts running Probing Client software simulating one Virtual Client, and running at the same time as Load Machines.|
|**Probing Client software**|See [*Probing Client*.](../console/getting_started.md#probing-client)|
|**Process Time**|<p>The time it takes WebLOAD to parse an HTTP response from the SUT and then populate the document-object model (DOM), in seconds.</p><p>The value posted in the Current Value column is the average time it took WebLOAD to parse an HTTP response during the last reporting interval.</p>|
|**Receive Time**|The elapsed time between receiving the first byte and the last byte.|
|**Report Portfolio**|See [*Portfolio*.](#_bookmark384)|
|<a name="_bookmark386"></a>**Resource Manager**|<p>Distributes and circulates WebLOAD testing resources (Virtual Clients and Probing Clients) amongst users on a "need to use" basis. The Resource Manager is packaged with a maximum number of Virtual Clients, Probing Clients and Connected Workstation ports, as defined by the WebLOAD package.</p><p>With the Resource Manager, every WebLOAD Console can operate in Standalone Workstation mode or Connected Workstation mode.</p>|
|**Response Data Size**|<p>The size, in bytes, of all the HTTP responses sent by the SUT during the last reporting interval.</p><p>WebLOAD uses this value to calculate Throughput (bytes per second).</p>|
|**Response Time**|<p>The time it takes the SUT to send the object of an HTTP request back to a Virtual Client, in seconds. In other words, the time from the end of the HTTP request until the Virtual Client has received the complete item it requested.</p><p>The value posted in the Current Value column is the average time it took the SUT to respond to an HTTP request during the last reporting interval.</p>|
|**Responses**|<p>The number of times the SUT responded to an HTTP request during the last reporting interval.</p><p>This number should match the number of successful hits.</p>|
|**Round Time**|<p>The time it takes one Virtual Client to finish one complete iteration of a script, in seconds.</p><p>The value posted in the Current Value column is the average time it took the Virtual Clients to finish one complete iteration of the script during the last reporting interval.</p>|
|**Rounds**|The total number of times the Virtual Clients attempted to run the script during the last reporting interval.|
|**Rounds Per Second**|<p>The number of times the Virtual Clients attempted to run the script, divided by the elapsed time, in seconds.</p><p>The value posted in the Current Value column is the number (sum) of attempts (both successful and unsuccessful) per second during the last reporting interval.</p>|
|**Send Time**|<p>The time it takes the Virtual Client to write an HTTP request to the SUT, in seconds.</p><p>The value posted in the Current Value column is the average time it took the Virtual Clients to write a request to the SUT during the last reporting interval.</p>|
|**Server Performance Measurements**|<p>If you selected Performance Monitor statistics for the report, WebLOAD creates a row for them and reports their values in the Statistics Report.</p><p>For definitions of the statistics, see the Server Monitor Definition dialog box.</p><p>Be selective when choosing server performance measurements , otherwise the system resources required to manage the data might affect the Console.</p>|
|**Session Tree**|A graphic representation of a Load Template and status. It illustrates the different components of a test session, including Load Machines and Probing Clients, the scripts that they execute, and their status.|
|**Single Client**|See [*Probing Client*.](../console/getting_started.md#probing-client)|
|**Standard Deviation**|The average amount the measurement varies from the average since the beginning of the test.|
|**Successful Connections**|<p>The total number of times the Virtual Clients were able to successfully connect to the SUT during the last reporting interval.</p><p>This number is always less than or equal to the number of successful hits because several hits might use the same HTTP connection if the Persistent Connection option is enabled.</p>|
|**Successful Hits**|The total number of times the Virtual Clients made an HTTP request and received the correct HTTP response from the SUT during the last reporting interval. Each request for each gif, jpeg, html file, etc., is a single hit.|
|**Successful Hits Per Second**|<p>The number of times the Virtual Clients obtained the correct HTTP response to their HTTP requests divided by the elapsed time, in seconds.</p><p>The value posted in the Current Value column is the number (sum) of successful HTTP requests per second during the last reporting interval.</p>|
|**Successful Pages Per Second**|The value posted in the Current Value column is the number (sum) of successful requests per second during the last reporting interval.|
|**Successful Rounds**|The total number of times the Virtual Clients completed one iteration of the script during the last reporting interval.|
|**Successful Rounds Per Second**|<p>The number of times the Virtual Clients completed an entire iteration of the script, divided by the elapsed time, in seconds.</p><p>The value posted in the Current Value column is the number (sum) of successful iterations of the script per second during the last reporting interval.</p>|
|<a name="_bookmark387"></a>**SUT**|The system running the Web application currently under test. The SUT (System Under Test) is accessed by clients through its URL address. The SUT can reside on any machine or on multiple machines, anywhere on the global Internet or your local intranet.|
|**Template**|See [*Load Template*.](#load_template)|
|<a name="templates_gallery"></a>**Templates Gallery**|The Templates Gallery is a single entity that contains predefined templates, user-defined templates, and portfolios.|
|**Test Program**|See [*Test Script*.](#_bookmark389)|
|<a name="_bookmark389"></a>**Test Script**|The script. This defines the test scenario used in your Load Session. Scripts are written in JavaScript.|
|**Test Template**|See [*Load Template*.](#load_template)|
|**TestTalk**|The network agent. This program enables communication between the Console and the host computers participating in the test.|
|**Throttle Control**|A WebLOAD component that enables you to dynamically change the Load Size while a test session is in progress.|
|**Throughput (Bytes Per Second)**|The average number of bytes per second transmitted from the SUT to the Virtual Clients running the script during the last reporting interval. In other words, this is the amount of the Response Data Size, divided by the number of seconds in the reporting interval.|
|**Time to First Byte**|The time that elapsed since a request was sent until the Virtual Client received the first byte of data.|
|**User-defined Automatic Data Collection**|<p>If you have Automatic Data Collection enabled, WebLOAD creates three counters for each GET and POST statement in the script:</p><p>- The total number of times the Get and Post statements occurred</p><p>- The number of times the statements succeeded</p><p>- The number of times the statements failed during the last reporting interval.</p>|
|**User-defined counters**|<p>Your own counters that you can add to scripts using the SendCounter() and the SendMeasurement() functions (see the *WebLOAD Scripting Guide*). If there is a user-defined counter in the script that you are running, WebLOAD reports the counter’s values in the Statistics Report.</p><p>The row heading is the name (argument) of the counter. That is, the row heading is the string in parenthesis in the SendCounter() or SendMeasurement() function call.</p><p>The value reported is the number of times the counter was incremented during the last reporting interval.</p>|
|**User-defined timer**|<p>Timers that you can add to scripts to keep track of the amount of time it takes to complete specific actions (see the *WebLOAD Scripting Guide*). If there are any timers in the scripts that you are running, WebLOAD reports their values in the Statistics Report.</p><p>The row heading is the name (argument) of the timer. That is, the row heading is the string in parenthesis in the SetTimer() function call. The timer represents the time it takes to complete all the actions between the SetTimer() call and its corresponding SendTimer() call, in seconds.</p><p>The value posted is the average time it took a Virtual Client to complete the actions between the pair of timer calls, in seconds, during the last reporting interval.</p>|
|**User-defined Transaction counters**|<p>Transaction functions that you can add to scripts for functional tests (see the *WebLOAD Scripting Guide*). If there is a user-defined transaction function in the script that you are running, WebLOAD reports three counters for it in the Statistics Report:</p><p>- The total number of times the transaction occurred</p><p>- The number of times a transaction succeeded</p><p>- The number of times a transaction failed during the last reporting interval.</p><p>The row heading is the name (argument) of the transaction. That is, the row heading is the string in parenthesis in the BeginTransaction() function call.</p>|
|**User-defined Transactions timers**|<p>A timer for user-defined transaction functions. If there is a user-defined transaction function in the script that you are running, WebLOAD reports a timer for it in the Statistics Report.</p><p>The row heading is the name (argument) of the user- defined transaction. That is, the row heading is the string in parenthesis in the BeginTransaction() function call.</p><p>The timer represents the average time it took to complete all the actions between the BeginTransaction() call and its corresponding EndTransaction() call, in seconds, during the last reporting interval.</p>|
|**Virtual Client**|<p>Artificial entities run by Load Generators. Each such entity is a perfect simulation of a real client accessing the System Under Test (SUT) through a Web browser.</p><p>Virtual Clients generate HTTP calls that access the SUT. The Load Generators that run Virtual Clients can reside anywhere on the Internet or on your local intranet. scripts are executed by all the Virtual Clients in parallel, achieving simultaneous access to the SUT. The size of the load on your SUT is determined by the number of Virtual Clients being generated. You may define as many Virtual Clients as needed, up to the maximum</p><p>supported by your WebLOAD "package."</p>|
|**WebLOAD Analytics**|WebLOAD Analytics enables you to analyze data, and create custom, informative reports after running a WebLOAD test session.|
|**WebLOAD Console**|See [*Console*.](#_bookmark379)|
|**WebLOAD Recorder**|An easy-to-use tool for recording, creating, and authoring protocol scripts for the WebLOAD environment.|
|**WebLOAD Load Template**|See [*Load Template*.](#load_template)|
|**WebLoad Session**|See [*Load Session*.](#load_sessions)|
|**WebLOAD Wizard**|A WebLOAD Wizard that steps you through the configuration process. Each screen of the WebLOAD Wizard contains text explaining the configuration process. The WebLOAD Wizard enables you to create a basic Load Template. After using the demo, you can use the Console ribbon to add functionality not available through the WebLOAD Wizard.|
|**WebRM**|See [*Resource Manager*.](#_bookmark386)|



